{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b46b9d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib.request as request\n",
    "\n",
    "def download_and_load_file(file_path: str, url: str):\n",
    "    \"\"\"下载，并加载指令微调数据集\n",
    "\n",
    "    Args:\n",
    "        file_path (str): 文件地址\n",
    "        url (str): URL\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        with request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, 'w', encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    else:\n",
    "        with open(file_path, 'r', encoding=\"utf-8\") as file:\n",
    "            text_data = file.read()\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "data = download_and_load_file(file_path=\"instruction-data.json\", url=(\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75665ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Below is an instruction that describes a task.Write a response that appropriately completes the request.\\n\\n### Instruction:\\nIdentify the correct spelling of the following word.\\n\\n### Input:\\nOcassion\\n\\n### Response:\\nThe correct spelling is 'Occasion.'\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_input(entry: dict[str, str]) -> str:\n",
    "    \"\"\"格式化输入\n",
    "\n",
    "    Args:\n",
    "        entry (dict[str, str]): 输入字典（JSON）\n",
    "\n",
    "    Returns:\n",
    "        str: 格式化指令微调数据\n",
    "    \"\"\"\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task.\"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "    input_text = (f\"\\n\\n### Input:\\n{entry['input']}\" if entry['input'] else \"\")\n",
    "    return instruction_text + input_text\n",
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "model_input + desired_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "931b0df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分数据集\n",
    "train_portion = int(len(data) * 0.85) # 使用85%的数据集作为训练集\n",
    "test_portion = int(len(data) * 0.1)   # 使用10%的数据集作为测试集\n",
    "val_portion = len(data) - train_portion - test_portion # 使用剩余（5%）数据集作为验证集\n",
    "\n",
    "# 通过切片索引划分数据集\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion+test_portion]\n",
    "val_data = data[train_portion + test_portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dcddae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tiktoken.core import Encoding\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    \"\"\"创建指令微调数据集\n",
    "\n",
    "    Args:\n",
    "        Dataset (Dataset): PyTorch Dataset\n",
    "    \"\"\"\n",
    "    def __init__(self, data: list[dict[str, str]], tokenizer: Encoding) -> None:\n",
    "        \"\"\"创建指令微调数据集\n",
    "\n",
    "        Args:\n",
    "            data (list[dict[str, str]]): 原始指令数据\n",
    "            tokenizer (Encoding): 分词器\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry=entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "        \n",
    "    def __getitem__(self, index: int):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f7d9489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[    0,     1,     2,     3,     4],\n",
       "         [    5,     6, 50256, 50256, 50256],\n",
       "         [    7,     8,     9, 50256, 50256]], device='cuda:0'),\n",
       " tensor([[    1,     2,     3,     4, 50256],\n",
       "         [    6, 50256,  -100,  -100,  -100],\n",
       "         [    8,     9, 50256,  -100,  -100]], device='cuda:0'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def custom_collate_draft(batch: Dataset, pad_token_id: int=50256, ignore_index: int=-100, allowed_max_length: int=None, device: str=\"cuda\") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"数据集聚合函数\n",
    "\n",
    "    Args:\n",
    "        batch (Dataset): 批次\n",
    "        pad_token_id (int, optional): Padding Token ID. Defaults to 50256.\n",
    "        ignore_index (int, optional): 掩码ID. Defaults to -100.\n",
    "        allowed_max_length (int, optional): 允许序列的最大长度. Defaults to None.\n",
    "        device (str, optional): 变量存储设备. Defaults to \"cuda\".\n",
    "\n",
    "    Returns:\n",
    "        tuple[torch.Tensor, torch.Tensor]: 输入和目标\n",
    "    \"\"\"\n",
    "    batch_max_length = max(len(item)+1 for item in batch) # 找到批次最长的序列\n",
    "    inputs_list, target_list = [], []\n",
    "    \n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        \n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        )\n",
    "        \n",
    "        inputs  = torch.tensor(padded[:-1]) # 删除之前添加的额外填充词元\n",
    "        targets = torch.tensor(padded[1:])  # 因为已经添加了额外一个词元，因此直接从index=1处开始切片即可\n",
    "        \n",
    "        # 将目标序列中除第一个填充词元外的所有填充词元都替换为ignore_index\n",
    "        mask = targets == pad_token_id # 设置mask为boolean张量（向量），形状与targtes一致，比较pad_token_id，等于pad_token_id的为true\n",
    "        indices = torch.nonzero(mask).squeeze() # 但torch.nonzero返回格式会包含多个维度，继续使用squeeze将1轴去除，得到展平为一个维度的张量\n",
    "        if indices.numel() > 1:\n",
    "            # 随后大于1的表示包含不止一个pad_token_id的序列，将末尾1个pad_token_id之后的pad_token_id全部设置为ignore_index即可\n",
    "            targets[indices[1:]] = ignore_index\n",
    "        \n",
    "        if allowed_max_length is not None:\n",
    "            # 根据allowed_max_length截断输入和目标到允许的最大长度即可\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "        \n",
    "        inputs_list.append(inputs)\n",
    "        target_list.append(targets)\n",
    "        \n",
    "    inputs_tensor = torch.stack(inputs_list).to(device) # 输入列表变成一个张量，并转移到目标设备\n",
    "    target_tensor = torch.stack(target_list).to(device)\n",
    "    return inputs_tensor, target_tensor\n",
    "\n",
    "inputs1 = [0, 1, 2, 3, 4]\n",
    "inputs2 = [5, 6]\n",
    "inputs3 = [7, 8, 9]\n",
    "batch = (inputs1, inputs2, inputs3)\n",
    "inputs_tensor, target_tensor = custom_collate_draft(batch=batch)\n",
    "inputs_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c704cda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 61, 768])\n"
     ]
    }
   ],
   "source": [
    "# 创建数据集加载器\n",
    "from functools import partial\n",
    "import tiktoken\n",
    "import torch.nn as nn\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "custom_collate_fn = partial(\n",
    "    custom_collate_draft,\n",
    "    device=\"cuda\",\n",
    "    allowed_max_length=1024\n",
    ")\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(data=train_data, tokenizer=tokenizer)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, collate_fn=custom_collate_fn, shuffle=True, drop_last=True, num_workers=num_workers)\n",
    "\n",
    "val_dataset = InstructionDataset(data=val_data, tokenizer=tokenizer)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, collate_fn=custom_collate_fn, shuffle=True, drop_last=True, num_workers=num_workers)\n",
    "\n",
    "test_dataset = InstructionDataset(data=test_data, tokenizer=tokenizer)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, collate_fn=custom_collate_fn, shuffle=True, drop_last=True, num_workers=num_workers)\n",
    "\n",
    "emb = nn.Embedding(50257, 768, device=\"cuda\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)\n",
    "    print(emb(inputs).shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b4b99e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-30 16:11:07.540402: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-30 16:11:08.352843: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-30 16:11:11.115676: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n",
      "Output text:\n",
      " Hello there you two – I think it's too early to draw any specific conclusions or conclusions about where Trump may be taking you.\n",
      "\n",
      "File already exists and is up-to-date: gpt2/355M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/355M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/355M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/355M/vocab.bpe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel2(\n",
       "  (token_embeddings): Embedding(50257, 1024)\n",
       "  (position_embeddings): Embedding(1024, 1024)\n",
       "  (dropout_embeddings): Dropout(p=0.0, inplace=False)\n",
       "  (transformer_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (pre_layer_norm): LayerNorm()\n",
       "      (post_layer_nrom): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (query_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (key_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (feed_forward): FeedForwardLayer(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (pre_layer_norm): LayerNorm()\n",
       "      (post_layer_nrom): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (query_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (key_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (feed_forward): FeedForwardLayer(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (pre_layer_norm): LayerNorm()\n",
       "      (post_layer_nrom): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (query_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (key_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (feed_forward): FeedForwardLayer(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (pre_layer_norm): LayerNorm()\n",
       "      (post_layer_nrom): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (query_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (key_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (feed_forward): FeedForwardLayer(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (pre_layer_norm): LayerNorm()\n",
       "      (post_layer_nrom): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (query_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (key_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (feed_forward): FeedForwardLayer(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (pre_layer_norm): LayerNorm()\n",
       "      (post_layer_nrom): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (query_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (key_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (feed_forward): FeedForwardLayer(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (pre_layer_norm): LayerNorm()\n",
       "      (post_layer_nrom): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (query_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (key_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (feed_forward): FeedForwardLayer(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (pre_layer_norm): LayerNorm()\n",
       "      (post_layer_nrom): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (query_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (key_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (feed_forward): FeedForwardLayer(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (pre_layer_norm): LayerNorm()\n",
       "      (post_layer_nrom): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (query_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (key_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (feed_forward): FeedForwardLayer(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (pre_layer_norm): LayerNorm()\n",
       "      (post_layer_nrom): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (query_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (key_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (feed_forward): FeedForwardLayer(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (pre_layer_norm): LayerNorm()\n",
       "      (post_layer_nrom): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (query_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (key_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (feed_forward): FeedForwardLayer(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (pre_layer_norm): LayerNorm()\n",
       "      (post_layer_nrom): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (query_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (key_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (feed_forward): FeedForwardLayer(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (pre_layer_norm): LayerNorm()\n",
       "      (post_layer_nrom): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (query_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (key_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (feed_forward): FeedForwardLayer(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (pre_layer_norm): LayerNorm()\n",
       "      (post_layer_nrom): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (query_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (key_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (feed_forward): FeedForwardLayer(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (pre_layer_norm): LayerNorm()\n",
       "      (post_layer_nrom): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (query_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (key_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (feed_forward): FeedForwardLayer(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (pre_layer_norm): LayerNorm()\n",
       "      (post_layer_nrom): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (query_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (key_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (feed_forward): FeedForwardLayer(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (pre_layer_norm): LayerNorm()\n",
       "      (post_layer_nrom): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (query_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (key_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (feed_forward): FeedForwardLayer(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (pre_layer_norm): LayerNorm()\n",
       "      (post_layer_nrom): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (query_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (key_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (feed_forward): FeedForwardLayer(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (pre_layer_norm): LayerNorm()\n",
       "      (post_layer_nrom): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (query_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (key_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (feed_forward): FeedForwardLayer(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (pre_layer_norm): LayerNorm()\n",
       "      (post_layer_nrom): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (query_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (key_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (feed_forward): FeedForwardLayer(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (pre_layer_norm): LayerNorm()\n",
       "      (post_layer_nrom): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (query_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (key_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (feed_forward): FeedForwardLayer(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (pre_layer_norm): LayerNorm()\n",
       "      (post_layer_nrom): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (query_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (key_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (feed_forward): FeedForwardLayer(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (pre_layer_norm): LayerNorm()\n",
       "      (post_layer_nrom): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (query_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (key_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (feed_forward): FeedForwardLayer(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (pre_layer_norm): LayerNorm()\n",
       "      (post_layer_nrom): LayerNorm()\n",
       "      (multi_head_attention): MultiHeadAttention(\n",
       "        (query_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (key_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (value_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (feed_forward): FeedForwardLayer(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from GPTModel import GPTModel2, load_weights_into_gpt\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    'vocab_size': 50257,    # 词汇表大小\n",
    "    'context_length': 1024, # 上下文维度\n",
    "    'drop_rate': 0.0,       # Dropout 率\n",
    "    'qkv_bias': True        # 查询-键-值偏置\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\":  {\"emb_dim\": 768,  \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\":  {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\":    {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "\n",
    "setttings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "model = GPTModel2(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4442811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task.Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "# 基准评估\n",
    "torch.manual_seed(123)\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23e5481b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Below is an instruction that describes a task.Write a response that appropriately completes the request.\\n\\n### Instruction:\\nConvert the active sentence to passive: 'The chef cooks the meal every day.'\\n\\n### Instruction:\\n\\nConvert the active sentence to passive: 'The chef cooks the meal every day.'\\n\\n### Instruction:\\n\\nConvert the active\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用generate函数生成模型的回复\n",
    "from GPTModel import generate, text_to_token_ids, token_ids_to_text\n",
    "token_ids = generate(\n",
    "    model=model.to(\"cuda\"),\n",
    "    idx=text_to_token_ids(text=input_text, tokenizer=tokenizer).to(\"cuda\"),\n",
    "    context_size=BASE_CONFIG['context_length'],\n",
    "    max_new_tokens=35,\n",
    "    eos_id=50256\n",
    ")\n",
    "generate_text = token_ids_to_text(token_ids=token_ids, tokenizer=tokenizer)\n",
    "generate_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69b8c6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"### Instruction:\\n\\nConvert the active sentence to passive: 'The chef cooks the meal every day.'\\n\\n### Instruction:\\n\\nConvert the active\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_text = generate_text[len(input_text):].strip()\n",
    "response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ff6db1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n",
      "Text 1:  tensor([7.4540e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2:  tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n",
      "tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n",
      "Targets batch 1: effort moves you\n",
      "Ouputs batch 1: Armed heNetflix\n",
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n",
      "tensor(10.7940)\n",
      "Flattened Logits: torch.Size([6, 50257])\n",
      "Flattened Targets: torch.Size([6])\n",
      "tensor(10.7940)\n",
      "Characters: 20479\n",
      "Tokens: 5145\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "Training loss: 10.98758316040039\n",
      "Validation loss: 10.98110580444336\n",
      "Training Loss:4.013571500778198\n",
      "Validation Loss:3.9755326747894286\n"
     ]
    }
   ],
   "source": [
    "from pre_training import calc_loss_loader, train_model_simple, plot_losses\n",
    "torch.manual_seed(123)\n",
    "# 首先计算模型在训练集和验证集上的初始损失\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, \"cuda\", num_batchs=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, \"cuda\", num_batchs=5)\n",
    "print(f\"Training Loss:{train_loss}\")\n",
    "print(f\"Validation Loss:{val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8eea58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 执行训练（训练完毕，直接加载模型参数）\n",
    "# torch.manual_seed(123)\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "# num_epochs = 2\n",
    "# train_losses, val_losses, token_seen = train_model_simple(\n",
    "#     model=model,\n",
    "#     train_loader=train_loader,\n",
    "#     valid_loader=val_loader,\n",
    "#     optimizer=optimizer,\n",
    "#     device=\"cuda\",\n",
    "#     start_context=format_input(val_data[0]),\n",
    "#     tokenizer=tokenizer,\n",
    "#     num_epochs=num_epochs,\n",
    "#     eval_freq=5,\n",
    "#     eval_iter=5\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b62ace6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "# plot_losses(epochs_tensor, token_seen=token_seen, train_losses=train_losses, val_losse=val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d70c069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型参数\n",
    "import re\n",
    "\n",
    "# file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL)}-sft.pth\"\n",
    "# torch.save(model.state_dict(), file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9797296a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [02:32<00:00,  1.38s/it]\n"
     ]
    }
   ],
   "source": [
    "# 加载模型\n",
    "model.load_state_dict(torch.load(\"gpt2-medium355M-sft.pth\"))\n",
    "# 基于测试集生成回复，创建评估数据集\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "    input_text = format_input(entry=entry)\n",
    "    \n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(text=input_text, tokenizer=tokenizer),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG['context_length'],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    \n",
    "    generated_text = token_ids_to_text(token_ids=token_ids, tokenizer=tokenizer)\n",
    "    \n",
    "    response_text = (\n",
    "        generate_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "    \n",
    "    test_data[i]['model_response'] = response_text\n",
    "    \n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
